{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0eD_rT4g1EX"
      },
      "source": [
        "## IMPORT STATEMENTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C2L86wiMuNqa"
      },
      "outputs": [],
      "source": [
        "# Import Statements\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3qnmtUIg6Oi"
      },
      "source": [
        "## SET UP FOR DEVICE AGNOSTIC CODE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNYFc8XTuNqc",
        "outputId": "49ef08c7-2ac6-424d-bc69-e99de0f349e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check if GPU is available\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "c042a_rtuNqd",
        "outputId": "bbe0e74e-fd4a-44d7-bae3-7dca9488e254"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda:0'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU4fWvW1hA73"
      },
      "source": [
        "## DATA LOADING AND PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKCZWjF3uNqd",
        "outputId": "47445e2c-5bef-43af-94ce-97b4f4421459"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount the google drive (RUN ONLY IN COLAB)\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jwfQBJ0MuNqd"
      },
      "outputs": [],
      "source": [
        "# Set up data directory path\n",
        "TRAIN_DATA_DIR = \"/content/drive/My Drive/Data/inaturalist_12K/train\"\n",
        "TEST_DATA_DIR = \"/content/drive/My Drive/Data/inaturalist_12K/val\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "cebH2ID5hgX_"
      },
      "outputs": [],
      "source": [
        "def data_transformations(image_size=(224, 224), data_augment=False):\n",
        "\n",
        "  # Define transformations to be applied (Base Transformations)\n",
        "  transformations = [\n",
        "      transforms.Resize(image_size),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225]) # NOTE:- I am planning to use EfficientNetV2 so using the same values as used for that network\n",
        "  ]\n",
        "\n",
        "  # If Augmentation is needed, add them to transform list\n",
        "  if data_augment:\n",
        "      transformations += [\n",
        "          transforms.RandomHorizontalFlip(0.05),\n",
        "          transforms.RandomVerticalFlip(0.05),\n",
        "          transforms.RandomRotation(degrees=20),\n",
        "          transforms.RandomApply([transforms.ColorJitter(0.2, 0.2, 0.2, 0.2)], p=0.05),\n",
        "          transforms.RandomApply([transforms.GaussianBlur(3)], p=0.05)\n",
        "      ]\n",
        "\n",
        "  transformer = transforms.Compose(transformations)\n",
        "\n",
        "  return transformer\n",
        "\n",
        "\n",
        "def get_train_and_val_dataloaders(train_data_dir, image_size=(224, 224), data_augment=False, valset_size=0.2, batch_size=16):\n",
        "\n",
        "  transformer = data_transformations(image_size, data_augment)\n",
        "\n",
        "  # Dowload the total_train dataset\n",
        "  total_trainset = torchvision.datasets.ImageFolder(root = train_data_dir, transform=transformer)\n",
        "  classnames = total_trainset.classes\n",
        "\n",
        "  # Split the total_train data into train data and val data\n",
        "  labels = [label for _, label in total_trainset.samples]\n",
        "\n",
        "  train_indices, val_indices = train_test_split(\n",
        "                                  range(len(total_trainset)),\n",
        "                                  test_size=valset_size,\n",
        "                                  stratify=labels,\n",
        "                                  random_state=42\n",
        "                                  )\n",
        "\n",
        "  trainset = torch.utils.data.Subset(total_trainset, train_indices)\n",
        "  valset = torch.utils.data.Subset(total_trainset, val_indices)\n",
        "\n",
        "  # Create the dataloaders\n",
        "  trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                            shuffle=True, num_workers=2)\n",
        "\n",
        "  valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
        "                                          shuffle=False, num_workers=2)\n",
        "\n",
        "  return trainloader, valloader, classnames\n",
        "\n",
        "\n",
        "\n",
        "def get_test_dataloader(test_data_dir, image_size=(224, 224), batch_size=8):\n",
        "\n",
        "  transformer = data_transformations(image_size, False)\n",
        "\n",
        "  #Download the test data\n",
        "  testset = torchvision.datasets.ImageFolder(root=test_data_dir, transform=transformer)\n",
        "\n",
        "\n",
        "\n",
        "  testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                          shuffle=False, num_workers=2)\n",
        "\n",
        "  return testloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "DgHxrVhWrkqX"
      },
      "outputs": [],
      "source": [
        "image_size = (224, 224)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "PSFemsbKK2Ze"
      },
      "outputs": [],
      "source": [
        "trainloader, valloader, classnames = get_train_and_val_dataloaders(TRAIN_DATA_DIR, image_size=image_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ro7VkemAhJs8"
      },
      "source": [
        "## MODEL CLASS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "C23aonrxuNqe"
      },
      "outputs": [],
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, image_size, in_channels=3, num_classes=10,\n",
        "                 num_filters=[64, 64, 64, 64, 64], kernel_size=[3, 3, 3, 3, 3],\n",
        "                 activation_fn=nn.ReLU, fc_layer_size=2048,\n",
        "                 batchnorm=False, dropout=0.0):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        h, w = image_size\n",
        "\n",
        "        # Block 1\n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=num_filters[0], kernel_size=kernel_size[0])\n",
        "        h, w = h - kernel_size[0] + 1, w - kernel_size[0] + 1\n",
        "        self.batchnorm1 = nn.BatchNorm2d(num_filters[0]) if batchnorm else nn.Identity()\n",
        "        self.activation1 = activation_fn()\n",
        "        self.dropout1 = nn.Dropout2d(dropout) if dropout!=0 else nn.Identity()\n",
        "        self.maxpool1 = nn.MaxPool2d(2, 2)\n",
        "        h, w = h//2, w//2\n",
        "\n",
        "        # Block 2\n",
        "        self.conv2 = nn.Conv2d(in_channels=num_filters[0], out_channels=num_filters[1], kernel_size=kernel_size[1])\n",
        "        h, w = h - kernel_size[1] + 1, w - kernel_size[1] + 1\n",
        "        self.batchnorm2 = nn.BatchNorm2d(num_filters[1]) if batchnorm else nn.Identity()\n",
        "        self.activation2 = activation_fn()\n",
        "        self.dropout2 = nn.Dropout2d(dropout) if dropout!=0 else nn.Identity()\n",
        "        self.maxpool2 = nn.MaxPool2d(2, 2)\n",
        "        h, w = h//2, w//2\n",
        "\n",
        "        # Block 3\n",
        "        self.conv3 = nn.Conv2d(in_channels=num_filters[1], out_channels=num_filters[2], kernel_size=kernel_size[2])\n",
        "        h, w = h - kernel_size[2] + 1, w - kernel_size[2] + 1\n",
        "        self.batchnorm3 = nn.BatchNorm2d(num_filters[2]) if batchnorm else nn.Identity()\n",
        "        self.activation3 = activation_fn()\n",
        "        self.dropout3 = nn.Dropout2d(dropout) if dropout!=0 else nn.Identity()\n",
        "        self.maxpool3 = nn.MaxPool2d(2, 2)\n",
        "        h, w = h//2, w//2\n",
        "\n",
        "        # Block 4\n",
        "        self.conv4 = nn.Conv2d(in_channels=num_filters[2], out_channels=num_filters[3], kernel_size=kernel_size[3])\n",
        "        h, w = h - kernel_size[3] + 1, w - kernel_size[3] + 1\n",
        "        self.batchnorm4 = nn.BatchNorm2d(num_filters[3]) if batchnorm else nn.Identity()\n",
        "        self.activation4 = activation_fn()\n",
        "        self.dropout4 = nn.Dropout2d(dropout) if dropout!=0 else nn.Identity()\n",
        "        self.maxpool4 = nn.MaxPool2d(2, 2)\n",
        "        h, w = h//2, w//2\n",
        "\n",
        "        # Block 5\n",
        "        self.conv5 = nn.Conv2d(in_channels=num_filters[3], out_channels=num_filters[4], kernel_size=kernel_size[4])\n",
        "        h, w = h - kernel_size[4] + 1, w - kernel_size[4] + 1\n",
        "        self.batchnorm5 = nn.BatchNorm2d(num_filters[4]) if batchnorm else nn.Identity()\n",
        "        self.activation5 = activation_fn()\n",
        "        self.dropout5 = nn.Dropout2d(dropout) if dropout!=0 else nn.Identity()\n",
        "        self.maxpool5 = nn.MaxPool2d(2, 2)\n",
        "        h, w = h//2, w//2\n",
        "\n",
        "        # Flattening layer\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc_layer = nn.Linear(in_features=num_filters[4] * h * w, out_features=fc_layer_size)\n",
        "        self.batchnorm_fc = nn.BatchNorm1d(fc_layer_size) if batchnorm else nn.Identity()\n",
        "        self.act_fc = activation_fn()\n",
        "        self.drop_fc = nn.Dropout(dropout) if dropout!=0 else nn.Identity()\n",
        "\n",
        "        # Output layer\n",
        "        self.out = nn.Linear(in_features=fc_layer_size, out_features=num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Block 1\n",
        "        x = self.conv1(x)\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.activation1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.maxpool1(x)\n",
        "\n",
        "        # Block 2\n",
        "        x = self.conv2(x)\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.activation2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.maxpool2(x)\n",
        "\n",
        "        # Block 3\n",
        "        x = self.conv3(x)\n",
        "        x = self.batchnorm3(x)\n",
        "        x = self.activation3(x)\n",
        "        x = self.dropout3(x)\n",
        "        x = self.maxpool3(x)\n",
        "\n",
        "        # Block 4\n",
        "        x = self.conv4(x)\n",
        "        x = self.batchnorm4(x)\n",
        "        x = self.activation4(x)\n",
        "        x = self.dropout4(x)\n",
        "        x = self.maxpool4(x)\n",
        "\n",
        "        # Block 5\n",
        "        x = self.conv5(x)\n",
        "        x = self.batchnorm5(x)\n",
        "        x = self.activation5(x)\n",
        "        x = self.dropout5(x)\n",
        "        x = self.maxpool5(x)\n",
        "\n",
        "        # Flatten\n",
        "        x = self.flatten(x)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = self.fc_layer(x)\n",
        "        x = self.batchnorm_fc(x)\n",
        "        x = self.act_fc(x)\n",
        "        x = self.drop_fc(x)\n",
        "\n",
        "        # Output layer\n",
        "        x = self.out(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_P6yuhaCuiS",
        "outputId": "02cb69f7-6fe3-4998-971f-c4da670367cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CNNModel(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (batchnorm1): Identity()\n",
              "  (activation1): ReLU()\n",
              "  (dropout1): Identity()\n",
              "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (batchnorm2): Identity()\n",
              "  (activation2): ReLU()\n",
              "  (dropout2): Identity()\n",
              "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (batchnorm3): Identity()\n",
              "  (activation3): ReLU()\n",
              "  (dropout3): Identity()\n",
              "  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (batchnorm4): Identity()\n",
              "  (activation4): ReLU()\n",
              "  (dropout4): Identity()\n",
              "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (batchnorm5): Identity()\n",
              "  (activation5): ReLU()\n",
              "  (dropout5): Identity()\n",
              "  (maxpool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc_layer): Linear(in_features=1600, out_features=2048, bias=True)\n",
              "  (batchnorm_fc): Identity()\n",
              "  (act_fc): ReLU()\n",
              "  (drop_fc): Identity()\n",
              "  (out): Linear(in_features=2048, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = CNNModel(image_size)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOmjCWo4w0o1"
      },
      "source": [
        "## TRAINING AND EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "7i9viVI9y1V5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "def train_model(model, trainloader, valloader, criterion, optimizer, device, epochs=10):\n",
        "\n",
        "    train_epoch_losses = []\n",
        "    train_epoch_accuracies = []\n",
        "\n",
        "\n",
        "    val_epoch_losses = []\n",
        "    val_epoch_accuracies = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        train_running_loss = 0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        for data in tqdm(trainloader):\n",
        "\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_running_loss += loss.item() * inputs.size(0)\n",
        "            train_total += inputs.size(0)\n",
        "            train_correct += torch.sum(labels == torch.argmax(outputs, dim=1)).item()\n",
        "\n",
        "        train_epoch_loss = train_running_loss / train_total\n",
        "        train_epoch_accuracy = 100 * train_correct / train_total\n",
        "\n",
        "        train_epoch_losses.append(train_epoch_loss)\n",
        "        train_epoch_accuracies.append(train_epoch_accuracy)\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        val_running_loss = 0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data in tqdm(valloader):\n",
        "\n",
        "                inputs, labels = data[0].to(device), data[1].to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_running_loss += loss.item() * inputs.size(0)\n",
        "                val_total += inputs.size(0)\n",
        "                val_correct += torch.sum(labels == torch.argmax(outputs, dim=1)).item()\n",
        "\n",
        "        val_epoch_loss = val_running_loss / val_total\n",
        "        val_epoch_accuracy = 100 * val_correct / val_total\n",
        "\n",
        "        val_epoch_losses.append(val_epoch_loss)\n",
        "        val_epoch_accuracies.append(val_epoch_accuracy)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_epoch_loss:.3f}, Train Acc: {train_epoch_accuracy:.2f}%, Val Loss: {val_epoch_loss:.3f}, Val Acc: {val_epoch_accuracy:.2f}%\")\n",
        "\n",
        "    return train_epoch_losses, train_epoch_accuracies, val_epoch_losses, val_epoch_accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "rrILJVDIznrl"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, testloader, criterion, device):\n",
        "  # Set the model to Evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  # Values to keep track of\n",
        "  running_loss = 0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data in tqdm(testloader):\n",
        "\n",
        "      inputs, labels = data[0].to(device), data[1].to(device)\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      running_loss += loss.item() * inputs.size(0)\n",
        "      total += inputs.size(0)\n",
        "      correct += torch.sum(labels == torch.argmax(outputs, dim=1)).item()\n",
        "\n",
        "  test_loss = running_loss / total\n",
        "  test_accuracy = (correct / total) * 100\n",
        "\n",
        "  print(f\"Test Loss: {test_loss:.3f}, Test Acc: {test_accuracy:.2f}%\")\n",
        "\n",
        "  return test_loss, test_accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Jqu27K8IztHK"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkSyQxQdov8W",
        "outputId": "cc69cfd2-927b-49cb-c69d-57f1cb065642"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 501/501 [01:57<00:00,  4.25it/s]\n",
            "100%|██████████| 126/126 [00:26<00:00,  4.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Train Loss: 2.311, Train Acc: 9.48%, Val Loss: 2.303, Val Acc: 9.99%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 501/501 [01:48<00:00,  4.61it/s]\n",
            "100%|██████████| 126/126 [00:25<00:00,  4.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10, Train Loss: 2.304, Train Acc: 9.78%, Val Loss: 2.303, Val Acc: 9.99%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 501/501 [01:48<00:00,  4.63it/s]\n",
            "100%|██████████| 126/126 [00:26<00:00,  4.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10, Train Loss: 2.304, Train Acc: 9.12%, Val Loss: 2.303, Val Acc: 10.09%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 501/501 [01:47<00:00,  4.65it/s]\n",
            "100%|██████████| 126/126 [00:25<00:00,  4.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10, Train Loss: 2.304, Train Acc: 9.64%, Val Loss: 2.303, Val Acc: 10.09%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 501/501 [01:47<00:00,  4.67it/s]\n",
            "100%|██████████| 126/126 [00:25<00:00,  4.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10, Train Loss: 2.304, Train Acc: 9.76%, Val Loss: 2.303, Val Acc: 9.99%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 501/501 [01:47<00:00,  4.64it/s]\n",
            "100%|██████████| 126/126 [00:25<00:00,  4.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10, Train Loss: 2.304, Train Acc: 9.57%, Val Loss: 2.303, Val Acc: 10.09%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 501/501 [01:47<00:00,  4.65it/s]\n",
            "100%|██████████| 126/126 [00:25<00:00,  4.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10, Train Loss: 2.304, Train Acc: 10.02%, Val Loss: 2.303, Val Acc: 9.99%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 501/501 [01:45<00:00,  4.73it/s]\n",
            "100%|██████████| 126/126 [00:26<00:00,  4.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10, Train Loss: 2.304, Train Acc: 9.29%, Val Loss: 2.303, Val Acc: 9.99%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 501/501 [01:47<00:00,  4.66it/s]\n",
            "100%|██████████| 126/126 [00:26<00:00,  4.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10, Train Loss: 2.304, Train Acc: 9.64%, Val Loss: 2.303, Val Acc: 9.99%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 501/501 [01:47<00:00,  4.67it/s]\n",
            "100%|██████████| 126/126 [00:26<00:00,  4.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10, Train Loss: 2.304, Train Acc: 9.04%, Val Loss: 2.303, Val Acc: 9.99%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "([2.3105565779750536,\n",
              "  2.3038416414477663,\n",
              "  2.3039181630313026,\n",
              "  2.3038147626863013,\n",
              "  2.3038577751728586,\n",
              "  2.3038967442518468,\n",
              "  2.3037263104059744,\n",
              "  2.3039017121493446,\n",
              "  2.3040772961462377,\n",
              "  2.3041392147555935],\n",
              " [9.48038970771921,\n",
              "  9.780164876342743,\n",
              "  9.118161378965775,\n",
              "  9.642767924056958,\n",
              "  9.755183612290782,\n",
              "  9.567824131901075,\n",
              "  10.017486884836373,\n",
              "  9.293030227329503,\n",
              "  9.642767924056958,\n",
              "  9.043217586809893],\n",
              " [2.302867354927482,\n",
              "  2.3029153780503706,\n",
              "  2.302903371138292,\n",
              "  2.3031853519595944,\n",
              "  2.302911263483983,\n",
              "  2.3029766730614356,\n",
              "  2.302807408732015,\n",
              "  2.3028145369949873,\n",
              "  2.302782053714032,\n",
              "  2.3029784717998067],\n",
              " [9.99000999000999,\n",
              "  9.99000999000999,\n",
              "  10.08991008991009,\n",
              "  10.08991008991009,\n",
              "  9.99000999000999,\n",
              "  10.08991008991009,\n",
              "  9.99000999000999,\n",
              "  9.99000999000999,\n",
              "  9.99000999000999,\n",
              "  9.99000999000999])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_model(model, trainloader, valloader, criterion, optimizer, device, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk7o_fRXCtNA"
      },
      "source": [
        "## WANDB HYPERPARAMETER SWEEP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXz_7fC8Hbv7"
      },
      "outputs": [],
      "source": [
        "def get_activation_function(name):\n",
        "  if name == \"leaky_relu\":\n",
        "    return nn.LeakyReLU\n",
        "  elif name == \"parametric_relu\":\n",
        "    return nn.PReLU\n",
        "  elif name == \"gelu\":\n",
        "    return nn.GELU\n",
        "  elif name == \"silu\":\n",
        "    return nn.SiLU\n",
        "  elif name == \"mish\":\n",
        "    return nn.Mish\n",
        "  return nn.ReLU\n",
        "\n",
        "def get_num_filters(name):\n",
        "  if name == \"equal16\":\n",
        "    return [16, 16, 16, 16, 16]\n",
        "  elif name == \"equal32\":\n",
        "    return [32, 32, 32, 32, 32]\n",
        "  elif name == \"equal64\":\n",
        "    return [64, 64, 64, 64, 64]\n",
        "  elif name == \"doubling16\":\n",
        "    return [16, 32, 64, 128, 256]\n",
        "  elif name == \"doubling32\":\n",
        "    return [32, 64, 128, 256, 512]\n",
        "  elif name == \"halving256\":\n",
        "    return [256, 128, 64, 32, 16]\n",
        "  else:\n",
        "    return [100, 80, 50, 80, 100]\n",
        "\n",
        "def get_kernel_size(name):\n",
        "  if name == \"constant5\":\n",
        "    return [5, 5, 5, 5, 5]\n",
        "  elif name == \"constant7\":\n",
        "    return [7, 7, 7, 7, 7]\n",
        "  elif name == \"decreasing\":\n",
        "    return [11, 7, 5, 3, 1]\n",
        "  elif name == \"increasing\":\n",
        "    return [1, 3, 5, 7, 11]\n",
        "  return [3, 3, 3, 3, 3]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SX-FuJvrDzJU"
      },
      "outputs": [],
      "source": [
        "def sweep_hyperparameters(config=None):\n",
        "\n",
        "  with wandb.init(config=config):\n",
        "\n",
        "    config = wandb.config\n",
        "    wandb.run.name = f\"activation_{str(config.activation)}_filters_{str(config.num_filters)}_lr_{config.learning_rate}_kernel_{config.kernel_size}_fc_size_{config.fc_layer_size}\"\n",
        "\n",
        "    # Log in my details\n",
        "    wandb.config.update({\"NAME\": \"SIDDHANT BARANWAL\", \"ROLL NO.\": \"DA24M021\"})\n",
        "\n",
        "    image_size=(224, 224)\n",
        "\n",
        "    TRAIN_DATA_DIR = \"/content/drive/My Drive/Data/inaturalist_12K/train\"\n",
        "    trainloader, valloader, classnames = get_train_and_val_dataloaders(TRAIN_DATA_DIR, image_size=image_size, data_augment=config.data_augment, valset_size=0.2, batch_size=config.batch_size)\n",
        "\n",
        "\n",
        "    model = CNNModel(image_size, num_filters=get_num_filters(config.num_filters), kernel_size=get_kernel_size(config.kernel_size),\n",
        "                     activation_fn=get_activation_function(config.activation), batchnorm=config.batch_norm, dropout=config.dropout,\n",
        "                     fc_layer_size=config.fc_layer_size)\n",
        "    model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
        "\n",
        "    train_losses, train_accuracies, val_losses, val_accuracies = train_model(model, trainloader, valloader, criterion, optimizer, device, epochs=10)\n",
        "\n",
        "    # Log the evaluation metrics\n",
        "    wandb.log({\n",
        "        \"train_losses\": train_losses,\n",
        "        \"train_accuracies\": train_accuracies,\n",
        "        \"val_losses\": val_losses,\n",
        "        \"val_accuracies\": val_accuracies,\n",
        "        \"val_accuracy\": val_accuracies[0]\n",
        "    })\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ti-kX14lpXpt"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    \"method\" : \"bayes\",\n",
        "    \"metric\" : {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
        "    \"parameters\" : {\n",
        "        \"data_augment\" : {\"values\" : [True, False]},\n",
        "        \"batch_norm\" : {\"values\" : [True, False]},\n",
        "        \"dropout\" : {\"values\" : [0.0, 0.2, 0.4]},\n",
        "        \"learning_rate\" : {\"values\" : [0.01, 0.001, 0.0005, 0.0001]},\n",
        "        \"activation\" : {\"values\" : [\"relu\", \"leaky_relu\", \"parametric_relu\",\n",
        "                                    \"gelu\", \"silu\", \"mish\"]},\n",
        "        \"num_filters\" : {\"values\" : [\"equal16\", \"equal32\", \"equal64\", \"doubling16\", \"doubling32\", \"halving256\"]},\n",
        "        \"kernel_size\" : {\"values\" : [\"constant3\", \"constant5\", \"constant7\", \"decreasing\", \"increasing\"]},\n",
        "        \"fc_layer_size\" : {\"values\": [2048, 1024, 512]},\n",
        "        \"batch_size\": {\"values\": [8, 16, 32]}\n",
        "    }\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, project = \"da24m021_da6401_assignment2\")\n",
        "wandb.agent(sweep_id, function = sweep_hyperparameters, count = 50)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".da6401_2_venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
