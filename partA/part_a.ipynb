{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## IMPORT STATEMENTS"
      ],
      "metadata": {
        "id": "F0eD_rT4g1EX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "C2L86wiMuNqa"
      },
      "outputs": [],
      "source": [
        "# Import Statements\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SET UP FOR DEVICE AGNOSTIC CODE"
      ],
      "metadata": {
        "id": "o3qnmtUIg6Oi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cNYFc8XTuNqc",
        "outputId": "21fb769b-a685-452d-8203-aaa1fb6dd58e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Check is GPU is available\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "c042a_rtuNqd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "04bc4efe-427a-4df4-d167-9a2feda570e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATA LOADING AND PREPROCESSING"
      ],
      "metadata": {
        "id": "vU4fWvW1hA73"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zKCZWjF3uNqd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c8357e6-9728-4de9-c567-0ef0f123d3ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount the google drive (RUN ONLY IN COLAB)\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jwfQBJ0MuNqd"
      },
      "outputs": [],
      "source": [
        "# Set up data directory path\n",
        "TRAIN_DATA_DIR = \"/content/drive/My Drive/Data/inaturalist_12K/train\"\n",
        "TEST_DATA_DIR = \"/content/drive/My Drive/Data/inaturalist_12K/val\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = (300, 300)\n",
        "data_augment = False\n",
        "valset_size = 0.2\n",
        "batch_size = 8\n",
        "\n",
        "\n",
        "# Define transformations to be applied\n",
        "base_transforms = [\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "]\n",
        "\n",
        "\n",
        "# If Augmentation is needed, add them to transform list\n",
        "train_transforms = base_transforms.copy()\n",
        "if data_augment:\n",
        "    train_transforms += [\n",
        "        transforms.RandomHorizontalFlip(0.2),\n",
        "        transforms.RandomRotation(degrees=20),\n",
        "        transforms.RandomApply([transforms.ColorJitter(0.2, 0.2, 0.2, 0.2)], p=0.1),\n",
        "        transforms.RandomApply([transforms.GaussianBlur(3)], p=0.1)\n",
        "    ]\n",
        "\n",
        "# Apply Compose to the transform lists\n",
        "train_transform = transforms.Compose(train_transforms)\n",
        "test_transform = transforms.Compose(base_transforms)\n",
        "\n",
        "# Dowload the total_train data.\n",
        "total_trainset = torchvision.datasets.ImageFolder(root = TRAIN_DATA_DIR, transform=train_transform)\n",
        "\n",
        "# Split the total_train data into train data and val data\n",
        "targets = [target for _, target in total_trainset.samples]\n",
        "\n",
        "train_indices, val_indices = train_test_split(\n",
        "                                range(len(total_trainset)),\n",
        "                                test_size=valset_size,\n",
        "                                stratify=targets,\n",
        "                                random_state=42\n",
        "                                )\n",
        "\n",
        "trainset = torch.utils.data.Subset(total_trainset, train_indices)\n",
        "valset = torch.utils.data.Subset(total_trainset, val_indices)\n",
        "\n",
        "\n",
        "#Download the test data\n",
        "testset = torchvision.datasets.ImageFolder(root=TEST_DATA_DIR, transform=test_transform)\n",
        "\n",
        "\n",
        "\n",
        "# Create the dataloaders\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
        "                                        shuffle=False, num_workers=2)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                        shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "cebH2ID5hgX_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MODEL CLASS"
      ],
      "metadata": {
        "id": "Ro7VkemAhJs8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "C23aonrxuNqe"
      },
      "outputs": [],
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, image_size, in_channels=3, num_classes=10,\n",
        "                 num_filters=[16, 32, 64, 128, 256], kernel_size=3,\n",
        "                 activation_fn=nn.ReLU, fc_layer_size=2048,\n",
        "                 batchnorm=False, dropout=0.0):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        h, w = image_size\n",
        "\n",
        "        # Block 1\n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=num_filters[0], kernel_size=kernel_size)\n",
        "        h, w = h - kernel_size + 1, w - kernel_size + 1\n",
        "        self.batchnorm1 = nn.BatchNorm2d(num_filters[0]) if batchnorm else nn.Identity()\n",
        "        self.activation1 = activation_fn()\n",
        "        self.dropout1 = nn.Dropout2d(dropout) if dropout!=0 else nn.Identity()\n",
        "        self.maxpool1 = nn.MaxPool2d(2, 2)\n",
        "        h, w = h//2, w//2\n",
        "\n",
        "        # Block 2\n",
        "        self.conv2 = nn.Conv2d(in_channels=num_filters[0], out_channels=num_filters[1], kernel_size=kernel_size)\n",
        "        h, w = h - kernel_size + 1, w - kernel_size + 1\n",
        "        self.batchnorm2 = nn.BatchNorm2d(num_filters[1]) if batchnorm else nn.Identity()\n",
        "        self.activation2 = activation_fn()\n",
        "        self.dropout2 = nn.Dropout2d(dropout) if dropout!=0 else nn.Identity()\n",
        "        self.maxpool2 = nn.MaxPool2d(2, 2)\n",
        "        h, w = h//2, w//2\n",
        "\n",
        "        # Block 3\n",
        "        self.conv3 = nn.Conv2d(in_channels=num_filters[1], out_channels=num_filters[2], kernel_size=kernel_size)\n",
        "        h, w = h - kernel_size + 1, w - kernel_size + 1\n",
        "        self.batchnorm3 = nn.BatchNorm2d(num_filters[2]) if batchnorm else nn.Identity()\n",
        "        self.activation3 = activation_fn()\n",
        "        self.dropout3 = nn.Dropout2d(dropout) if dropout!=0 else nn.Identity()\n",
        "        self.maxpool3 = nn.MaxPool2d(2, 2)\n",
        "        h, w = h//2, w//2\n",
        "\n",
        "        # Block 4\n",
        "        self.conv4 = nn.Conv2d(in_channels=num_filters[2], out_channels=num_filters[3], kernel_size=kernel_size)\n",
        "        h, w = h - kernel_size + 1, w - kernel_size + 1\n",
        "        self.batchnorm4 = nn.BatchNorm2d(num_filters[3]) if batchnorm else nn.Identity()\n",
        "        self.activation4 = activation_fn()\n",
        "        self.dropout4 = nn.Dropout2d(dropout) if dropout!=0 else nn.Identity()\n",
        "        self.maxpool4 = nn.MaxPool2d(2, 2)\n",
        "        h, w = h//2, w//2\n",
        "\n",
        "        # Block 5\n",
        "        self.conv5 = nn.Conv2d(in_channels=num_filters[3], out_channels=num_filters[4], kernel_size=kernel_size)\n",
        "        h, w = h - kernel_size + 1, w - kernel_size + 1\n",
        "        self.batchnorm5 = nn.BatchNorm2d(num_filters[4]) if batchnorm else nn.Identity()\n",
        "        self.activation5 = activation_fn()\n",
        "        self.dropout5 = nn.Dropout2d(dropout) if dropout!=0 else nn.Identity()\n",
        "        self.maxpool5 = nn.MaxPool2d(2, 2)\n",
        "        h, w = h//2, w//2\n",
        "\n",
        "        # Flattening layer\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc_layer = nn.Linear(in_features=num_filters[4] * h * w, out_features=fc_layer_size)\n",
        "        self.drop_fc = nn.Dropout(dropout) if dropout!=0 else nn.Identity()\n",
        "        self.act_fc = activation_fn()\n",
        "\n",
        "        # Output layer\n",
        "        self.out = nn.Linear(in_features=fc_layer_size, out_features=num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Block 1\n",
        "        x = self.conv1(x)\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.activation1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.maxpool1(x)\n",
        "\n",
        "        # Block 2\n",
        "        x = self.conv2(x)\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.activation2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.maxpool2(x)\n",
        "\n",
        "        # Block 3\n",
        "        x = self.conv3(x)\n",
        "        x = self.batchnorm3(x)\n",
        "        x = self.activation3(x)\n",
        "        x = self.dropout3(x)\n",
        "        x = self.maxpool3(x)\n",
        "\n",
        "        # Block 4\n",
        "        x = self.conv4(x)\n",
        "        x = self.batchnorm4(x)\n",
        "        x = self.activation4(x)\n",
        "        x = self.dropout4(x)\n",
        "        x = self.maxpool4(x)\n",
        "\n",
        "        # Block 5\n",
        "        x = self.conv5(x)\n",
        "        x = self.batchnorm5(x)\n",
        "        x = self.activation5(x)\n",
        "        x = self.dropout5(x)\n",
        "        x = self.maxpool5(x)\n",
        "\n",
        "        # Flatten\n",
        "        x = self.flatten(x)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = self.fc_layer(x)\n",
        "        x = self.drop_fc(x)\n",
        "        x = self.act_fc(x)\n",
        "\n",
        "        # Output layer\n",
        "        x = self.out(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNNModel(image_size)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_P6yuhaCuiS",
        "outputId": "d524bf25-66d7-48ba-d96d-4f12b2d14b86"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNNModel(\n",
              "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (batchnorm1): Identity()\n",
              "  (activation1): ReLU()\n",
              "  (dropout1): Identity()\n",
              "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (batchnorm2): Identity()\n",
              "  (activation2): ReLU()\n",
              "  (dropout2): Identity()\n",
              "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (batchnorm3): Identity()\n",
              "  (activation3): ReLU()\n",
              "  (dropout3): Identity()\n",
              "  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (batchnorm4): Identity()\n",
              "  (activation4): ReLU()\n",
              "  (dropout4): Identity()\n",
              "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (batchnorm5): Identity()\n",
              "  (activation5): ReLU()\n",
              "  (dropout5): Identity()\n",
              "  (maxpool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc_layer): Linear(in_features=12544, out_features=2048, bias=True)\n",
              "  (drop_fc): Identity()\n",
              "  (act_fc): ReLU()\n",
              "  (out): Linear(in_features=2048, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, trainloader, valloader, optimizer, criterion, device, epochs=10):\n",
        "  pass"
      ],
      "metadata": {
        "id": "7i9viVI9y1V5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, testloader, criterion, device):\n",
        "  pass"
      ],
      "metadata": {
        "id": "rrILJVDIznrl"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jqu27K8IztHK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}